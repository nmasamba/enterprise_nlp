{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0bff59",
   "metadata": {},
   "source": [
    "Summarisation creates a shorter version of a document or an article that captures all the important information. Along with translation, it is another example of a task that can be formulated as a sequence-to-sequence task. \n",
    "\n",
    "Summarisation can be:\n",
    "Extractive - extract the most relevant information from a document, or\n",
    "Abstractive - generate new text that captures the most relevant information.\n",
    "\n",
    "This guide shows how to:\n",
    "1. Finetune T5 on the California state bill subset of the BillSum dataset for abstractive summarisation.\n",
    "2. Use the finetuned model for inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51d8af",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
    "\n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec6861",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smaller California state bill subset of the BillSum dataset\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split the dataset\n",
    "billsum = billsum.train_test_split(test_size=0.2)\n",
    "\n",
    "# The two fields to use for modeling:\n",
    "# text: the text of the bill whichâ€™ll be the input to the model.\n",
    "# summary: a condensed version of text which will be the model target.\n",
    "billsum[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16389f98",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b36585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a T5 tokenizer to process text and summary\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix the input with a prompt so T5 knows this is a summarization task\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    # Use the keyword text_target argument when tokenizing labels\n",
    "    # Truncate sequences to be no longer than the maximum length set by the max_length parameter.\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033582ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
