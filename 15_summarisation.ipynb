{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e16a2d",
   "metadata": {},
   "source": [
    "Summarisation creates a shorter version of a document or an article that captures all the important information. Along with translation, it is another example of a task that can be formulated as a sequence-to-sequence task. \n",
    "\n",
    "Summarisation can be:\n",
    "Extractive - extract the most relevant information from a document, or\n",
    "Abstractive - generate new text that captures the most relevant information.\n",
    "\n",
    "This guide shows how to:\n",
    "1. Finetune T5 on the California state bill subset of the BillSum dataset for abstractive summarisation.\n",
    "2. Use the finetuned model for inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf4cff",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f117c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b108b07",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smaller California state bill subset of the BillSum dataset\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split the dataset\n",
    "billsum = billsum.train_test_split(test_size=0.2)\n",
    "\n",
    "# The two fields to use for modeling:\n",
    "# text: the text of the bill which’ll be the input to the model.\n",
    "# summary: a condensed version of text which will be the model target.\n",
    "billsum[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b6df0",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a T5 tokenizer to process text and summary\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix the input with a prompt so T5 knows this is a summarization task\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    # Use the keyword text_target argument when tokenizing labels\n",
    "    # Truncate sequences to be no longer than the maximum length set by the max_length parameter.\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac40c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c2031",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate this summarisation task, load the ROUGE metric\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2afbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that passes predictions and labels to compute() to calculate the ROUGE metric\n",
    "# Called during training\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771cd32",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "model.to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57262cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training hyperparameters in Seq2SeqTrainingArguments()\n",
    "# The only required parameter is output_dir\n",
    "# At the end of each epoch, the Trainer will evaluate the ROUGE metric and save the training checkpoint\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"summarisation_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Pass the training arguments to Seq2SeqTrainer...\n",
    "# along with the model, dataset, tokenizer, data collator, and compute_metrics() function\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Call train() to finetune the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f13a3",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e082d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text you’d like to summarise \n",
    "# For T5, you need to prefix your input depending on the task you’re working on...\n",
    "# e.g. for summarisation, prefix your input as shown below:\n",
    "text = \"summarize: The Inflation Reduction Act is a proposed piece of legislation\\\n",
    "that is supposed to lower prescription drug costs, health care costs, and energy costs.\\\n",
    "It's the most aggressive action on tackling the climate crisis (and maybe inflation?) in American history, \\\n",
    "which will lift up American workers and create good-paying, union jobs across the country. \\\n",
    "It promises to lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. \\\n",
    "And it nearly guarantees that no one making under $400,000 per year will pay a penny more in taxes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> inference within a pipeline()\n",
    "summarizer = pipeline(\"summarization\", model=\"summarisation_model\")\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> inference using PyTorch objects\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"summarisation_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# # Use the generate() method to generate the summarised text\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"stevhliu/my_awesome_billsum_model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=100, do_sample=False)\n",
    "# Decode the generated token ids back into text\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
